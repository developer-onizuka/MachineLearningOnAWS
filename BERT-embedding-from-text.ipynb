{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f591733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f189e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.1)\n",
      "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.10/dist-packages (4.0.9)\n",
      "Requirement already satisfied: pandas-profiling in /usr/local/lib/python3.10/dist-packages (3.6.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: ydata-profiling in /usr/local/lib/python3.10/dist-packages (from pandas-profiling) (4.6.3)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.7.0)\n",
      "Requirement already satisfied: scipy<1.12,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.11.4)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.5.3)\n",
      "Requirement already satisfied: matplotlib<3.9,>=3.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (3.8.2)\n",
      "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (2.5.2)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (6.0.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (3.1.2)\n",
      "Requirement already satisfied: visions==0.7.5 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (0.7.5)\n",
      "Requirement already satisfied: numpy<1.26,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.24.4)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.12.3)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (4.66.1)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.12.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.10)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.14.1)\n",
      "Requirement already satisfied: typeguard<5,>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (4.1.5)\n",
      "Requirement already satisfied: imagehash==4.3.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.9.3)\n",
      "Requirement already satisfied: dacite>=1.8 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.8.1)\n",
      "Requirement already satisfied: numba<0.59.0,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.57.1+1.g4157f3379)\n",
      "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (1.5.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (10.1.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions==0.7.5->visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions==0.7.5->visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (3.2.1)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from visions==0.7.5->visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (0.2.0)\n",
      "\u001b[33mWARNING: visions 0.7.5 does not provide the extra 'type-image-path'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba<0.59.0,>=0.56.0->ydata-profiling->pandas-profiling) (0.40.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling->pandas-profiling) (2023.3.post1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.3.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling->pandas-profiling) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling->pandas-profiling) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling->pandas-profiling) (4.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2023.11.17)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling) (0.5.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets widgetsnbextension pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c394965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "843cbf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "max_seq_length = 64\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "REVIEW_BODY_COLUMN = \"review_body\"\n",
    "REVIEW_ID_COLUMN = \"review_id\"\n",
    "\n",
    "LABEL_COLUMN = \"star_rating\"\n",
    "LABEL_VALUES = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00f87c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(LABEL_VALUES):\n",
    "    label_map[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fbfefd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2714802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7e32241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"BERT特徴量ベクトル\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id, review_id, date, label):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.review_id = review_id\n",
    "        self.date = date\n",
    "        self.label = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a460965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(object):\n",
    "    \"\"\"シーケンス分類で用いるトレーニング/テストの単一の入力\"\"\"\n",
    "\n",
    "    def __init__(self, text, review_id, date, label=None):\n",
    "        \"\"\"入力のコンストラクタ\n",
    "        Args:\n",
    "          text: 文字列。トークン化されていない一つ目のシーケンスのテキスト。\n",
    "            単一シーケンスのタスクではこのシーケンスのみを指定する。\n",
    "          label: (オプショナル) 文字列。サンプルのラベル。トレーニングや検証用のサンプルでは指定する。\n",
    "            テスト用のサンプルでは指定しない。\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.review_id = review_id\n",
    "        self.date = date\n",
    "        self.label = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3f9ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input(the_input, max_seq_length):\n",
    "    # まず、BERTが学習したデータ形式と合うようにデータを前処理する。\n",
    "    # 1. テキストを小文字にする（BERT lowercaseモデルを用いる場合）\n",
    "    # 2. トークン化する（例、\"sally says hi\" -> [\"sally\", \"says\", \"hi\"]）\n",
    "    # 3. 単語をWordPieceに分割（例、\"calling\" -> [\"call\", \"##ing\"]）\n",
    "    #\n",
    "    # この辺りの処理はTransformersライブラリのトークナイザーがまかなってくれます。\n",
    "\n",
    "    tokens = tokenizer.tokenize(the_input.text)\n",
    "    tokens.insert(0, '[CLS]')\n",
    "    tokens.append('[SEP]')\n",
    "    print(\"**{} tokens**\\n{}\\n\".format(len(tokens), tokens))\n",
    "\n",
    "    encode_plus_tokens = tokenizer.encode_plus(\n",
    "        the_input.text,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # 事前学習済みBERTの語彙ID。トークンを表す。（トークン数が `max_seq_length` 未満であれば0をパディングする）\n",
    "    input_ids = encode_plus_tokens[\"input_ids\"]\n",
    "\n",
    "    # BERTがどのトークンに注目するかを0/1で指定。`input_ids` のパディング部分のベクトル要素には0を割り当てる。\n",
    "    input_mask = encode_plus_tokens[\"attention_mask\"]\n",
    "\n",
    "    # テキスト分類のような単一シーケンスのタスクではセグメントIDは常に0とする。質問回答や次文予測のような2シーケンスタスクの場合は1を割り当てる。\n",
    "    segment_ids = [0] * max_seq_length\n",
    "\n",
    "    # それぞれのトレーニングデータの行のラベル（`star_rating` 1〜5）\n",
    "    label_id = label_map[the_input.label]\n",
    "\n",
    "    features = InputFeatures(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        label_id=label_id,\n",
    "        review_id=the_input.review_id,\n",
    "        date=the_input.date,\n",
    "        label=the_input.label,\n",
    "    )\n",
    "\n",
    "    print(\"**{} input_ids**\\n{}\\n\".format(len(features.input_ids), features.input_ids))\n",
    "    print(\"**{} input_mask**\\n{}\\n\".format(len(features.input_mask), features.input_mask))\n",
    "    print(\"**{} segment_ids**\\n{}\\n\".format(len(features.segment_ids), features.segment_ids))\n",
    "    print(\"**label_id**\\n{}\\n\".format(features.label_id))\n",
    "    print(\"**review_id**\\n{}\\n\".format(features.review_id))\n",
    "    print(\"**date**\\n{}\\n\".format(features.date))\n",
    "    print(\"**label**\\n{}\\n\".format(features.label))\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cac05b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs_to_tfrecord(inputs, output_file, max_seq_length):\n",
    "    # データをBERTが理解できるフォーマットに変換する\n",
    "    records = []\n",
    "    tf_record_writer = tf.io.TFRecordWriter(output_file)\n",
    "\n",
    "    for (input_idx, the_input) in enumerate(inputs):\n",
    "        if input_idx % 10000 == 0:\n",
    "            print(\"Writing input {} of {}\\n\".format(input_idx, len(inputs)))\n",
    "\n",
    "        features = convert_input(the_input, max_seq_length)\n",
    "\n",
    "        all_features = collections.OrderedDict()\n",
    "\n",
    "        # input_ids、input_mask、segment_ids、label_idsを含んだTFRecordを作成\n",
    "        all_features[\"input_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.input_ids))\n",
    "        all_features[\"input_mask\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.input_mask))\n",
    "        all_features[\"segment_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.segment_ids))\n",
    "        all_features[\"label_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[features.label_id]))\n",
    "\n",
    "        tf_record = tf.train.Example(features=tf.train.Features(feature=all_features))\n",
    "        tf_record_writer.write(tf_record.SerializeToString())\n",
    "\n",
    "        # Feature Storeに格納する、すべての特徴量を含んだレコードを作成\n",
    "        records.append(\n",
    "            {\n",
    "                \"input_ids\": features.input_ids,\n",
    "                \"input_mask\": features.input_mask,\n",
    "                \"segment_ids\": features.segment_ids,\n",
    "                \"label_id\": features.label_id,\n",
    "                \"review_id\": the_input.review_id,\n",
    "                \"date\": the_input.date,\n",
    "                \"label\": features.label,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    tf_record_writer.close()\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f3543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4a96b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07T12:05:09Z\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from time import strftime\n",
    "\n",
    "# timestamp = datetime.now().replace(microsecond=0).isoformat()\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "903d41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    [\n",
    "        5,\n",
    "        \"ABCD12345\",\n",
    "        \"\"\"I needed an \"antivirus\" application and know the quality of Norton products.  This was a no brainer for me and I am glad it was so simple to get.\"\"\",\n",
    "    ],\n",
    "    [\n",
    "        3,\n",
    "        \"EFGH12345\",\n",
    "        \"\"\"The problem with ElephantDrive is that it requires the use of Java. Since Java is notorious for security problems I haveit removed from all of my computers. What files I do have stored are photos.\"\"\",\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"IJKL2345\",\n",
    "        \"\"\"Terrible, none of my codes worked, and I can't uninstall it.  I think this product IS malware and viruses\"\"\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"star_rating\", \"review_id\", \"review_body\"])\n",
    "\n",
    "# Input クラスを使用して、データからサンプルを作成する。\n",
    "inputs = df.apply(\n",
    "    lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56eae43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>ABCD12345</td>\n",
       "      <td>I needed an \"antivirus\" application and know t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>EFGH12345</td>\n",
       "      <td>The problem with ElephantDrive is that it requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>IJKL2345</td>\n",
       "      <td>Terrible, none of my codes worked, and I can't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating  review_id                                        review_body\n",
       "0            5  ABCD12345  I needed an \"antivirus\" application and know t...\n",
       "1            3  EFGH12345  The problem with ElephantDrive is that it requ...\n",
       "2            1   IJKL2345  Terrible, none of my codes worked, and I can't..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3649f81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <__main__.Input object at 0x7f0b2fb4cbe0>\n",
       "1    <__main__.Input object at 0x7f0b2fb4de10>\n",
       "2    <__main__.Input object at 0x7f0b2fb4d780>\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1092e542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07T12:05:09Z\n"
     ]
    }
   ],
   "source": [
    "# date が Feature Store の仕様に合わせて ISO-8601 になっていることを確認\n",
    "print(inputs[0].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40100b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"./data.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1330704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input 0 of 3\n",
      "\n",
      "**37 tokens**\n",
      "['[CLS]', 'i', 'needed', 'an', '\"', 'anti', '##virus', '\"', 'application', 'and', 'know', 'the', 'quality', 'of', 'norton', 'products', '.', 'this', 'was', 'a', 'no', 'brain', '##er', 'for', 'me', 'and', 'i', 'am', 'glad', 'it', 'was', 'so', 'simple', 'to', 'get', '.', '[SEP]']\n",
      "\n",
      "**64 input_ids**\n",
      "[101, 1045, 2734, 2019, 1000, 3424, 23350, 1000, 4646, 1998, 2113, 1996, 3737, 1997, 10770, 3688, 1012, 2023, 2001, 1037, 2053, 4167, 2121, 2005, 2033, 1998, 1045, 2572, 5580, 2009, 2001, 2061, 3722, 2000, 2131, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**64 input_mask**\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**64 segment_ids**\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**label_id**\n",
      "4\n",
      "\n",
      "**review_id**\n",
      "ABCD12345\n",
      "\n",
      "**date**\n",
      "2024-01-07T12:05:09Z\n",
      "\n",
      "**label**\n",
      "5\n",
      "\n",
      "**42 tokens**\n",
      "['[CLS]', 'the', 'problem', 'with', 'elephant', '##drive', 'is', 'that', 'it', 'requires', 'the', 'use', 'of', 'java', '.', 'since', 'java', 'is', 'notorious', 'for', 'security', 'problems', 'i', 'have', '##it', 'removed', 'from', 'all', 'of', 'my', 'computers', '.', 'what', 'files', 'i', 'do', 'have', 'stored', 'are', 'photos', '.', '[SEP]']\n",
      "\n",
      "**64 input_ids**\n",
      "[101, 1996, 3291, 2007, 10777, 23663, 2003, 2008, 2009, 5942, 1996, 2224, 1997, 9262, 1012, 2144, 9262, 2003, 12536, 2005, 3036, 3471, 1045, 2031, 4183, 3718, 2013, 2035, 1997, 2026, 7588, 1012, 2054, 6764, 1045, 2079, 2031, 8250, 2024, 7760, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**64 input_mask**\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**64 segment_ids**\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**label_id**\n",
      "2\n",
      "\n",
      "**review_id**\n",
      "EFGH12345\n",
      "\n",
      "**date**\n",
      "2024-01-07T12:05:09Z\n",
      "\n",
      "**label**\n",
      "3\n",
      "\n",
      "**30 tokens**\n",
      "['[CLS]', 'terrible', ',', 'none', 'of', 'my', 'codes', 'worked', ',', 'and', 'i', 'can', \"'\", 't', 'un', '##ins', '##tal', '##l', 'it', '.', 'i', 'think', 'this', 'product', 'is', 'mal', '##ware', 'and', 'viruses', '[SEP]']\n",
      "\n",
      "**64 input_ids**\n",
      "[101, 6659, 1010, 3904, 1997, 2026, 9537, 2499, 1010, 1998, 1045, 2064, 1005, 1056, 4895, 7076, 9080, 2140, 2009, 1012, 1045, 2228, 2023, 4031, 2003, 15451, 8059, 1998, 18191, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**64 input_mask**\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**64 segment_ids**\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**label_id**\n",
      "0\n",
      "\n",
      "**review_id**\n",
      "IJKL2345\n",
      "\n",
      "**date**\n",
      "2024-01-07T12:05:09Z\n",
      "\n",
      "**label**\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "records = transform_inputs_to_tfrecord(inputs, output_file, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a50d807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c41204a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/mnt/amazon_reviews_2015.snappy.parquet\",columns=[\"star_rating\",\"review_id\",\"review_body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b7119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63c7f502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R2C20GSMIOZYVP'</td>\n",
       "      <td>b'I have made multiple purchases of this prosc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>b'RPI30SPP1J9U9'</td>\n",
       "      <td>b\"I am not sure if it's a product or storage p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>b'RKYY2ZQGUV06L'</td>\n",
       "      <td>b\"I was  hoping this had a stronger taste than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>b'RKYYAEA9G3CD4'</td>\n",
       "      <td>b'Awesome Tea!'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'R17ZQPU555KVR6'</td>\n",
       "      <td>b\"This tasty spread tastes just like a melted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905626</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R2341YPSNIJ3NB'</td>\n",
       "      <td>b\"I got this case for my violin, as my old one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905627</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R34HOANGHY4878'</td>\n",
       "      <td>b'just as excpected'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905628</th>\n",
       "      <td>4</td>\n",
       "      <td>b'R3APW14Y9V4QOP'</td>\n",
       "      <td>b\"It has ten really cool sounds, the beat step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905629</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R18BIAZS3JP0MI'</td>\n",
       "      <td>b'very clear sound thank you amazon i recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905630</th>\n",
       "      <td>4</td>\n",
       "      <td>b'R22EKJX8BS3YYJ'</td>\n",
       "      <td>b'Very nice rebound and sound.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41905631 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          star_rating          review_id  \\\n",
       "0                   5  b'R2C20GSMIOZYVP'   \n",
       "1                   3   b'RPI30SPP1J9U9'   \n",
       "2                   1   b'RKYY2ZQGUV06L'   \n",
       "3                   5   b'RKYYAEA9G3CD4'   \n",
       "4                   4  b'R17ZQPU555KVR6'   \n",
       "...               ...                ...   \n",
       "41905626            5  b'R2341YPSNIJ3NB'   \n",
       "41905627            5  b'R34HOANGHY4878'   \n",
       "41905628            4  b'R3APW14Y9V4QOP'   \n",
       "41905629            5  b'R18BIAZS3JP0MI'   \n",
       "41905630            4  b'R22EKJX8BS3YYJ'   \n",
       "\n",
       "                                                review_body  \n",
       "0         b'I have made multiple purchases of this prosc...  \n",
       "1         b\"I am not sure if it's a product or storage p...  \n",
       "2         b\"I was  hoping this had a stronger taste than...  \n",
       "3                                           b'Awesome Tea!'  \n",
       "4         b\"This tasty spread tastes just like a melted ...  \n",
       "...                                                     ...  \n",
       "41905626  b\"I got this case for my violin, as my old one...  \n",
       "41905627                               b'just as excpected'  \n",
       "41905628  b\"It has ten really cool sounds, the beat step...  \n",
       "41905629  b'very clear sound thank you amazon i recommen...  \n",
       "41905630                    b'Very nice rebound and sound.'  \n",
       "\n",
       "[41905631 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13d608b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_id'] = df['review_id'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62dbd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_body'] = df['review_body'].str.decode(\"utf-8\",\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30eaf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72c2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ee3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02ab5532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>R2C20GSMIOZYVP</td>\n",
       "      <td>I have made multiple purchases of this prosciu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>RPI30SPP1J9U9</td>\n",
       "      <td>I am not sure if it's a product or storage pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>RKYY2ZQGUV06L</td>\n",
       "      <td>I was  hoping this had a stronger taste than r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>RKYYAEA9G3CD4</td>\n",
       "      <td>Awesome Tea!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>R17ZQPU555KVR6</td>\n",
       "      <td>This tasty spread tastes just like a melted Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905626</th>\n",
       "      <td>5</td>\n",
       "      <td>R2341YPSNIJ3NB</td>\n",
       "      <td>I got this case for my violin, as my old one w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905627</th>\n",
       "      <td>5</td>\n",
       "      <td>R34HOANGHY4878</td>\n",
       "      <td>just as excpected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905628</th>\n",
       "      <td>4</td>\n",
       "      <td>R3APW14Y9V4QOP</td>\n",
       "      <td>It has ten really cool sounds, the beat step w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905629</th>\n",
       "      <td>5</td>\n",
       "      <td>R18BIAZS3JP0MI</td>\n",
       "      <td>very clear sound thank you amazon i recommende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41905630</th>\n",
       "      <td>4</td>\n",
       "      <td>R22EKJX8BS3YYJ</td>\n",
       "      <td>Very nice rebound and sound.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41905631 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          star_rating       review_id  \\\n",
       "0                   5  R2C20GSMIOZYVP   \n",
       "1                   3   RPI30SPP1J9U9   \n",
       "2                   1   RKYY2ZQGUV06L   \n",
       "3                   5   RKYYAEA9G3CD4   \n",
       "4                   4  R17ZQPU555KVR6   \n",
       "...               ...             ...   \n",
       "41905626            5  R2341YPSNIJ3NB   \n",
       "41905627            5  R34HOANGHY4878   \n",
       "41905628            4  R3APW14Y9V4QOP   \n",
       "41905629            5  R18BIAZS3JP0MI   \n",
       "41905630            4  R22EKJX8BS3YYJ   \n",
       "\n",
       "                                                review_body  \n",
       "0         I have made multiple purchases of this prosciu...  \n",
       "1         I am not sure if it's a product or storage pro...  \n",
       "2         I was  hoping this had a stronger taste than r...  \n",
       "3                                              Awesome Tea!  \n",
       "4         This tasty spread tastes just like a melted Re...  \n",
       "...                                                     ...  \n",
       "41905626  I got this case for my violin, as my old one w...  \n",
       "41905627                                  just as excpected  \n",
       "41905628  It has ten really cool sounds, the beat step w...  \n",
       "41905629  very clear sound thank you amazon i recommende...  \n",
       "41905630                       Very nice rebound and sound.  \n",
       "\n",
       "[41905631 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae7b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f15b84a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df Memory Usage: 13.552809612825513 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"df Memory Usage: {df.memory_usage(deep=True).sum() / 1024**3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7661cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandarallel in /usr/local/lib/python3.10/dist-packages (1.6.5)\n",
      "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pandarallel) (0.3.7)\n",
      "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.10/dist-packages (from pandarallel) (1.5.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from pandarallel) (5.9.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1->pandarallel) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a983f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1179aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73a885cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "import os\n",
    "os.environ['JOBLIB_TEMP_FOLDER'] = '/tmp'\n",
    "\n",
    "pandarallel.initialize(nb_workers=2, progress_bar=True, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bdf40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input クラスを使用して、データからサンプルを作成する。\n",
    "#inputs = df.apply(\n",
    "#    lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp),\n",
    "#    axis=1,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8347683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['JOBLIB_TEMP_FOLDER'] = '/tmp'\n",
    "#!export TMPDIR=/var/tmp\n",
    "#!pip3 install --no-cache-dir accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e2e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54c904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c1893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88911b0ae5ab48f38aadf08750551308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=20952816), Label(value='0 / 209528…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def func(x):\n",
    "#    return lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp)\n",
    "\n",
    "inputs = df.parallel_apply(\n",
    "    lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbecf43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1f93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f049d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <__main__.Input object at 0x7f0b2fb4c0d0>\n",
       "1    <__main__.Input object at 0x7f0b2fb4c2b0>\n",
       "2    <__main__.Input object at 0x7f0b2fb4cbb0>\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aea980b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"./data.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db4f28f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07T09:30:01Z\n"
     ]
    }
   ],
   "source": [
    "# date が Feature Store の仕様に合わせて ISO-8601 になっていることを確認\n",
    "print(inputs[0].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4675747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input 0 of 41905631\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m records \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_inputs_to_tfrecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m, in \u001b[0;36mtransform_inputs_to_tfrecord\u001b[0;34m(inputs, output_file, max_seq_length)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting input \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(input_idx, \u001b[38;5;28mlen\u001b[39m(inputs)))\n\u001b[0;32m---> 10\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m all_features \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# input_ids、input_mask、segment_ids、label_idsを含んだTFRecordを作成\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36mconvert_input\u001b[0;34m(the_input, max_seq_length)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_input\u001b[39m(the_input, max_seq_length):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# まず、BERTが学習したデータ形式と合うようにデータを前処理する。\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 1. テキストを小文字にする（BERT lowercaseモデルを用いる場合）\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# この辺りの処理はTransformersライブラリのトークナイザーがまかなってくれます。\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     tokens\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[CLS]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     tokens\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[SEP]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py:573\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m     escaped_special_toks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    568\u001b[0m         re\u001b[38;5;241m.\u001b[39mescape(s_tok\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m    569\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s_tok \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_added_tokens_decoder\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    570\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s_tok\u001b[38;5;241m.\u001b[39mspecial \u001b[38;5;129;01mand\u001b[39;00m s_tok\u001b[38;5;241m.\u001b[39mnormalized\n\u001b[1;32m    571\u001b[0m     ]\n\u001b[1;32m    572\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(escaped_special_toks) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)|\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.+?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 573\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_special_tokens:\n\u001b[1;32m    576\u001b[0m     no_split_token \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/lib/python3.10/re.py:209\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "records = transform_inputs_to_tfrecord(inputs, output_file, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4135685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5796a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc273ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc354c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30dac2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "my_bytes = b'apple,banana,kiwi'\n",
    "\n",
    "m = re.search(\"apple\", my_bytes.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1ee5b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='apple'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6051f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
