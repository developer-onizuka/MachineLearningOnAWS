{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f591733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f882eb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tqdm, safetensors, regex, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.13.1 huggingface-hub-0.20.2 regex-2023.12.25 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.36.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f189e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting widgetsnbextension\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas-profiling\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.9.0)\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ydata-profiling (from pandas-profiling)\n",
      "  Downloading ydata_profiling-4.6.3-py2.py3-none-any.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.6/357.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.7.0)\n",
      "Requirement already satisfied: scipy<1.12,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.11.0)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.5.2)\n",
      "Collecting matplotlib<3.9,>=3.2 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (2.0.2)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (6.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (3.1.2)\n",
      "Collecting visions[type_image_path]==0.7.5 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m431.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.26,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.22.2)\n",
      "Collecting htmlmin==0.1.12 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting phik<0.13,>=0.11.1 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading phik-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m793.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (4.66.1)\n",
      "Collecting seaborn<0.13,>=0.10.1 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multimethod<2,>=1.4 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading multimethod-1.10-py3-none-any.whl (9.9 kB)\n",
      "Collecting statsmodels<1,>=0.13.2 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading statsmodels-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting typeguard<5,>=4.1.2 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
      "Collecting imagehash==4.3.1 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wordcloud>=1.9.1 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.1/511.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dacite>=1.8 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba<0.59.0,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.57.1+1.gf851d279c)\n",
      "Collecting PyWavelets (from imagehash==4.3.1->ydata-profiling->pandas-profiling)\n",
      "  Downloading pywavelets-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (9.5.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (2.8.8)\n",
      "Collecting tangled-up-in-unicode>=0.0.4 (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling)\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (2.1.3)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling)\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling)\n",
      "  Downloading fonttools-4.47.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba<0.59.0,>=0.56.0->ydata-profiling->pandas-profiling) (0.40.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling->pandas-profiling) (2023.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling->pandas-profiling) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.1.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling->pandas-profiling) (2.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling->pandas-profiling) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2023.5.7)\n",
      "Collecting patsy>=0.5.4 (from statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Collecting numpy<1.26,>=1.16.0 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27096 sha256=aae913b71c71b3f4d8bceed095bfd299ae2b8d1dcc95bb7ee92da92fe79a482f\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, widgetsnbextension, typeguard, tangled-up-in-unicode, numpy, multimethod, kiwisolver, jupyterlab-widgets, fonttools, dacite, cycler, PyWavelets, patsy, contourpy, visions, statsmodels, matplotlib, imagehash, wordcloud, seaborn, phik, ipywidgets, ydata-profiling, pandas-profiling\n",
      "  Attempting uninstall: typeguard\n",
      "    Found existing installation: typeguard 4.0.0\n",
      "    Uninstalling typeguard-4.0.0:\n",
      "      Successfully uninstalled typeguard-4.0.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.2\n",
      "    Uninstalling numpy-1.22.2:\n",
      "      Successfully uninstalled numpy-1.22.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.12.0+nv23.7 requires numpy<1.24,>=1.22; python_version >= \"3.7\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyWavelets-1.5.0 contourpy-1.2.0 cycler-0.12.1 dacite-1.8.1 fonttools-4.47.0 htmlmin-0.1.12 imagehash-4.3.1 ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 kiwisolver-1.4.5 matplotlib-3.8.2 multimethod-1.10 numpy-1.24.4 pandas-profiling-3.6.6 patsy-0.5.6 phik-0.12.3 seaborn-0.12.2 statsmodels-0.14.1 tangled-up-in-unicode-0.2.0 typeguard-4.1.5 visions-0.7.5 widgetsnbextension-4.0.9 wordcloud-1.9.3 ydata-profiling-4.6.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets widgetsnbextension pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c394965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843cbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 11:54:43.804839: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491a143dbcf641399cc1ac9e9681f54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ef764e5ece486ba573f2e479440526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49718465da8343b78dc46fb3724d4140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b54be7c5a74583a6aaa885c6d1064c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "max_seq_length = 64\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "REVIEW_BODY_COLUMN = \"review_body\"\n",
    "REVIEW_ID_COLUMN = \"review_id\"\n",
    "\n",
    "LABEL_COLUMN = \"star_rating\"\n",
    "LABEL_VALUES = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f87c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(LABEL_VALUES):\n",
    "    label_map[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbfefd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2714802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e32241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"BERT特徴量ベクトル\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id, review_id, date, label):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.review_id = review_id\n",
    "        self.date = date\n",
    "        self.label = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a460965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(object):\n",
    "    \"\"\"シーケンス分類で用いるトレーニング/テストの単一の入力\"\"\"\n",
    "\n",
    "    def __init__(self, text, review_id, date, label=None):\n",
    "        \"\"\"入力のコンストラクタ\n",
    "        Args:\n",
    "          text: 文字列。トークン化されていない一つ目のシーケンスのテキスト。\n",
    "            単一シーケンスのタスクではこのシーケンスのみを指定する。\n",
    "          label: (オプショナル) 文字列。サンプルのラベル。トレーニングや検証用のサンプルでは指定する。\n",
    "            テスト用のサンプルでは指定しない。\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.review_id = review_id\n",
    "        self.date = date\n",
    "        self.label = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f9ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input(the_input, max_seq_length):\n",
    "    # まず、BERTが学習したデータ形式と合うようにデータを前処理する。\n",
    "    # 1. テキストを小文字にする（BERT lowercaseモデルを用いる場合）\n",
    "    # 2. トークン化する（例、\"sally says hi\" -> [\"sally\", \"says\", \"hi\"]）\n",
    "    # 3. 単語をWordPieceに分割（例、\"calling\" -> [\"call\", \"##ing\"]）\n",
    "    #\n",
    "    # この辺りの処理はTransformersライブラリのトークナイザーがまかなってくれます。\n",
    "\n",
    "    tokens = tokenizer.tokenize(the_input.text)\n",
    "    tokens.insert(0, '[CLS]')\n",
    "    tokens.append('[SEP]')\n",
    "    # print(\"**{} tokens**\\n{}\\n\".format(len(tokens), tokens))\n",
    "\n",
    "    encode_plus_tokens = tokenizer.encode_plus(\n",
    "        the_input.text,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # 事前学習済みBERTの語彙ID。トークンを表す。（トークン数が `max_seq_length` 未満であれば0をパディングする）\n",
    "    input_ids = encode_plus_tokens[\"input_ids\"]\n",
    "\n",
    "    # BERTがどのトークンに注目するかを0/1で指定。`input_ids` のパディング部分のベクトル要素には0を割り当てる。\n",
    "    input_mask = encode_plus_tokens[\"attention_mask\"]\n",
    "\n",
    "    # テキスト分類のような単一シーケンスのタスクではセグメントIDは常に0とする。質問回答や次文予測のような2シーケンスタスクの場合は1を割り当てる。\n",
    "    segment_ids = [0] * max_seq_length\n",
    "\n",
    "    # それぞれのトレーニングデータの行のラベル（`star_rating` 1〜5）\n",
    "    label_id = label_map[the_input.label]\n",
    "\n",
    "    features = InputFeatures(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        label_id=label_id,\n",
    "        review_id=the_input.review_id,\n",
    "        date=the_input.date,\n",
    "        label=the_input.label,\n",
    "    )\n",
    "\n",
    "    # print(\"**{} input_ids**\\n{}\\n\".format(len(features.input_ids), features.input_ids))\n",
    "    # print(\"**{} input_mask**\\n{}\\n\".format(len(features.input_mask), features.input_mask))\n",
    "    # print(\"**{} segment_ids**\\n{}\\n\".format(len(features.segment_ids), features.segment_ids))\n",
    "    # print(\"**label_id**\\n{}\\n\".format(features.label_id))\n",
    "    # print(\"**review_id**\\n{}\\n\".format(features.review_id))\n",
    "    # print(\"**date**\\n{}\\n\".format(features.date))\n",
    "    # print(\"**label**\\n{}\\n\".format(features.label))\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac05b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs_to_tfrecord(inputs, output_file, max_seq_length):\n",
    "    # データをBERTが理解できるフォーマットに変換する\n",
    "    records = []\n",
    "    tf_record_writer = tf.io.TFRecordWriter(output_file)\n",
    "\n",
    "    for (input_idx, the_input) in enumerate(inputs):\n",
    "        if input_idx % 10000 == 0:\n",
    "            print(\"Writing input {} of {}\\n\".format(input_idx, len(inputs)))\n",
    "\n",
    "        features = convert_input(the_input, max_seq_length)\n",
    "\n",
    "        all_features = collections.OrderedDict()\n",
    "\n",
    "        # input_ids、input_mask、segment_ids、label_idsを含んだTFRecordを作成\n",
    "        all_features[\"input_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.input_ids))\n",
    "        all_features[\"input_mask\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.input_mask))\n",
    "        all_features[\"segment_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.segment_ids))\n",
    "        all_features[\"label_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[features.label_id]))\n",
    "\n",
    "        tf_record = tf.train.Example(features=tf.train.Features(feature=all_features))\n",
    "        tf_record_writer.write(tf_record.SerializeToString())\n",
    "\n",
    "        # Feature Storeに格納する、すべての特徴量を含んだレコードを作成\n",
    "        records.append(\n",
    "            {\n",
    "                \"input_ids\": features.input_ids,\n",
    "                \"input_mask\": features.input_mask,\n",
    "                \"segment_ids\": features.segment_ids,\n",
    "                \"label_id\": features.label_id,\n",
    "                \"review_id\": the_input.review_id,\n",
    "                \"date\": the_input.date,\n",
    "                \"label\": features.label,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    tf_record_writer.close()\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f3543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a96b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-08T11:55:20Z\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from time import strftime\n",
    "\n",
    "# timestamp = datetime.now().replace(microsecond=0).isoformat()\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "903d41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    [\n",
    "        5,\n",
    "        \"ABCD12345\",\n",
    "        \"\"\"I needed an \"antivirus\" application and know the quality of Norton products.  This was a no brainer for me and I am glad it was so simple to get.\"\"\",\n",
    "    ],\n",
    "    [\n",
    "        3,\n",
    "        \"EFGH12345\",\n",
    "        \"\"\"The problem with ElephantDrive is that it requires the use of Java. Since Java is notorious for security problems I haveit removed from all of my computers. What files I do have stored are photos.\"\"\",\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"IJKL2345\",\n",
    "        \"\"\"Terrible, none of my codes worked, and I can't uninstall it.  I think this product IS malware and viruses\"\"\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"star_rating\", \"review_id\", \"review_body\"])\n",
    "\n",
    "# Input クラスを使用して、データからサンプルを作成する。\n",
    "inputs = df.apply(\n",
    "    lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56eae43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>ABCD12345</td>\n",
       "      <td>I needed an \"antivirus\" application and know t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>EFGH12345</td>\n",
       "      <td>The problem with ElephantDrive is that it requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>IJKL2345</td>\n",
       "      <td>Terrible, none of my codes worked, and I can't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating  review_id                                        review_body\n",
       "0            5  ABCD12345  I needed an \"antivirus\" application and know t...\n",
       "1            3  EFGH12345  The problem with ElephantDrive is that it requ...\n",
       "2            1   IJKL2345  Terrible, none of my codes worked, and I can't..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3649f81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <__main__.Input object at 0x7f1102405480>\n",
       "1    <__main__.Input object at 0x7f11024050f0>\n",
       "2    <__main__.Input object at 0x7f1102404100>\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1092e542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-08T11:55:20Z\n"
     ]
    }
   ],
   "source": [
    "# date が Feature Store の仕様に合わせて ISO-8601 になっていることを確認\n",
    "print(inputs[0].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40100b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"./data.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1330704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input 0 of 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "records = transform_inputs_to_tfrecord(inputs, output_file, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a50d807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c41204a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/mnt/amazon_reviews_2015.snappy.parquet\",columns=[\"star_rating\",\"review_id\",\"review_body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e04a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_df = df.tail(400000)\n",
    "validation_df = df.sample(n=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "621b7119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = df.head(2000000)\n",
    "train_df = df.sample(n=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7661d250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37360958</th>\n",
       "      <td>3</td>\n",
       "      <td>b'R14JRWZPN9JJ8O'</td>\n",
       "      <td>b'A bit goofy. Makes some good political point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32193167</th>\n",
       "      <td>4</td>\n",
       "      <td>b'R3S1ZGKY8EQN9P'</td>\n",
       "      <td>b'5-star performance, 2-star price.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13272080</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R2IQ1375QDFGIG'</td>\n",
       "      <td>b'Excelente!!!'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404381</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R1NV59K55BHI0O'</td>\n",
       "      <td>b'first of all this book is very helpful it he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026917</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R3G1NU4RZK81EE'</td>\n",
       "      <td>b'really slick and stays slick longtime, looks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816406</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R1A8YXRY5K3PUZ'</td>\n",
       "      <td>b'Amazing keyboard'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41078916</th>\n",
       "      <td>3</td>\n",
       "      <td>b'R27ZXYR2VCVJCJ'</td>\n",
       "      <td>b'too small'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067910</th>\n",
       "      <td>3</td>\n",
       "      <td>b'R30L5DD2UV4M1V'</td>\n",
       "      <td>b'A decent book to read with a child. It lists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971383</th>\n",
       "      <td>3</td>\n",
       "      <td>b'R26FY6PNPTSNWL'</td>\n",
       "      <td>b\"Doesn't fit my trailer hitch, but looks like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086759</th>\n",
       "      <td>4</td>\n",
       "      <td>b'R3T7XAOULCY5NY'</td>\n",
       "      <td>b'I was a little skeptical at first thinking t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          star_rating          review_id  \\\n",
       "37360958            3  b'R14JRWZPN9JJ8O'   \n",
       "32193167            4  b'R3S1ZGKY8EQN9P'   \n",
       "13272080            5  b'R2IQ1375QDFGIG'   \n",
       "1404381             5  b'R1NV59K55BHI0O'   \n",
       "6026917             5  b'R3G1NU4RZK81EE'   \n",
       "...               ...                ...   \n",
       "39816406            5  b'R1A8YXRY5K3PUZ'   \n",
       "41078916            3  b'R27ZXYR2VCVJCJ'   \n",
       "7067910             3  b'R30L5DD2UV4M1V'   \n",
       "20971383            3  b'R26FY6PNPTSNWL'   \n",
       "3086759             4  b'R3T7XAOULCY5NY'   \n",
       "\n",
       "                                                review_body  \n",
       "37360958  b'A bit goofy. Makes some good political point...  \n",
       "32193167               b'5-star performance, 2-star price.'  \n",
       "13272080                                    b'Excelente!!!'  \n",
       "1404381   b'first of all this book is very helpful it he...  \n",
       "6026917   b'really slick and stays slick longtime, looks...  \n",
       "...                                                     ...  \n",
       "39816406                                b'Amazing keyboard'  \n",
       "41078916                                       b'too small'  \n",
       "7067910   b'A decent book to read with a child. It lists...  \n",
       "20971383  b\"Doesn't fit my trailer hitch, but looks like...  \n",
       "3086759   b'I was a little skeptical at first thinking t...  \n",
       "\n",
       "[400000 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c7f502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32961526</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R1X8YO6MVKSR6M'</td>\n",
       "      <td>b'standard'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30241700</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R2DDEXG6H9O8G2'</td>\n",
       "      <td>b\"The game looks good remastered in HD.  I lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845194</th>\n",
       "      <td>5</td>\n",
       "      <td>b'RVSOZV5TXMORR'</td>\n",
       "      <td>b'A nice selection of tools to remove all sort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34884730</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R2YGCGRV2HJ91G'</td>\n",
       "      <td>b'Great product for a great price. We looked a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33577116</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R3SXTBD2U2M9SX'</td>\n",
       "      <td>b'Amazing product. Worth every penny'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32866146</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R1AM0WCUJUBTRB'</td>\n",
       "      <td>b'So comfortable - like walking on pillows!'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22333198</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R35W8TTXLW341O'</td>\n",
       "      <td>b\"I took a notepad to write down a few quotes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33572301</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R2RPVF53YMR9NS'</td>\n",
       "      <td>b'Bachman did a really good job on this model,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20664178</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R5M7N34BIR1Z'</td>\n",
       "      <td>b'I received blue.  Great product for my prote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481666</th>\n",
       "      <td>5</td>\n",
       "      <td>b'R326IQS9MQ2WJH'</td>\n",
       "      <td>b'Exactly what I was looking for!!!!'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          star_rating          review_id  \\\n",
       "32961526            5  b'R1X8YO6MVKSR6M'   \n",
       "30241700            5  b'R2DDEXG6H9O8G2'   \n",
       "8845194             5   b'RVSOZV5TXMORR'   \n",
       "34884730            5  b'R2YGCGRV2HJ91G'   \n",
       "33577116            5  b'R3SXTBD2U2M9SX'   \n",
       "...               ...                ...   \n",
       "32866146            5  b'R1AM0WCUJUBTRB'   \n",
       "22333198            5  b'R35W8TTXLW341O'   \n",
       "33572301            5  b'R2RPVF53YMR9NS'   \n",
       "20664178            5    b'R5M7N34BIR1Z'   \n",
       "481666              5  b'R326IQS9MQ2WJH'   \n",
       "\n",
       "                                                review_body  \n",
       "32961526                                        b'standard'  \n",
       "30241700  b\"The game looks good remastered in HD.  I lov...  \n",
       "8845194   b'A nice selection of tools to remove all sort...  \n",
       "34884730  b'Great product for a great price. We looked a...  \n",
       "33577116              b'Amazing product. Worth every penny'  \n",
       "...                                                     ...  \n",
       "32866146       b'So comfortable - like walking on pillows!'  \n",
       "22333198  b\"I took a notepad to write down a few quotes ...  \n",
       "33572301  b'Bachman did a really good job on this model,...  \n",
       "20664178  b'I received blue.  Great product for my prote...  \n",
       "481666                b'Exactly what I was looking for!!!!'  \n",
       "\n",
       "[2000000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13d608b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review_id'] = train_df['review_id'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62dbd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review_body'] = train_df['review_body'].str.decode(\"utf-8\",\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02ab5532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32961526</th>\n",
       "      <td>5</td>\n",
       "      <td>R1X8YO6MVKSR6M</td>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30241700</th>\n",
       "      <td>5</td>\n",
       "      <td>R2DDEXG6H9O8G2</td>\n",
       "      <td>The game looks good remastered in HD.  I loved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845194</th>\n",
       "      <td>5</td>\n",
       "      <td>RVSOZV5TXMORR</td>\n",
       "      <td>A nice selection of tools to remove all sorts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34884730</th>\n",
       "      <td>5</td>\n",
       "      <td>R2YGCGRV2HJ91G</td>\n",
       "      <td>Great product for a great price. We looked at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33577116</th>\n",
       "      <td>5</td>\n",
       "      <td>R3SXTBD2U2M9SX</td>\n",
       "      <td>Amazing product. Worth every penny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32866146</th>\n",
       "      <td>5</td>\n",
       "      <td>R1AM0WCUJUBTRB</td>\n",
       "      <td>So comfortable - like walking on pillows!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22333198</th>\n",
       "      <td>5</td>\n",
       "      <td>R35W8TTXLW341O</td>\n",
       "      <td>I took a notepad to write down a few quotes fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33572301</th>\n",
       "      <td>5</td>\n",
       "      <td>R2RPVF53YMR9NS</td>\n",
       "      <td>Bachman did a really good job on this model, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20664178</th>\n",
       "      <td>5</td>\n",
       "      <td>R5M7N34BIR1Z</td>\n",
       "      <td>I received blue.  Great product for my protein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481666</th>\n",
       "      <td>5</td>\n",
       "      <td>R326IQS9MQ2WJH</td>\n",
       "      <td>Exactly what I was looking for!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          star_rating       review_id  \\\n",
       "32961526            5  R1X8YO6MVKSR6M   \n",
       "30241700            5  R2DDEXG6H9O8G2   \n",
       "8845194             5   RVSOZV5TXMORR   \n",
       "34884730            5  R2YGCGRV2HJ91G   \n",
       "33577116            5  R3SXTBD2U2M9SX   \n",
       "...               ...             ...   \n",
       "32866146            5  R1AM0WCUJUBTRB   \n",
       "22333198            5  R35W8TTXLW341O   \n",
       "33572301            5  R2RPVF53YMR9NS   \n",
       "20664178            5    R5M7N34BIR1Z   \n",
       "481666              5  R326IQS9MQ2WJH   \n",
       "\n",
       "                                                review_body  \n",
       "32961526                                           standard  \n",
       "30241700  The game looks good remastered in HD.  I loved...  \n",
       "8845194   A nice selection of tools to remove all sorts ...  \n",
       "34884730  Great product for a great price. We looked at ...  \n",
       "33577116                 Amazing product. Worth every penny  \n",
       "...                                                     ...  \n",
       "32866146          So comfortable - like walking on pillows!  \n",
       "22333198  I took a notepad to write down a few quotes fr...  \n",
       "33572301  Bachman did a really good job on this model, i...  \n",
       "20664178  I received blue.  Great product for my protein...  \n",
       "481666                   Exactly what I was looking for!!!!  \n",
       "\n",
       "[2000000 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5d22035",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df['review_id'] = validation_df['review_id'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7ae7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df['review_body'] = validation_df['review_body'].str.decode(\"utf-8\",\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad389a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37360958</th>\n",
       "      <td>3</td>\n",
       "      <td>R14JRWZPN9JJ8O</td>\n",
       "      <td>A bit goofy. Makes some good political points....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32193167</th>\n",
       "      <td>4</td>\n",
       "      <td>R3S1ZGKY8EQN9P</td>\n",
       "      <td>5-star performance, 2-star price.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13272080</th>\n",
       "      <td>5</td>\n",
       "      <td>R2IQ1375QDFGIG</td>\n",
       "      <td>Excelente!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404381</th>\n",
       "      <td>5</td>\n",
       "      <td>R1NV59K55BHI0O</td>\n",
       "      <td>first of all this book is very helpful it help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026917</th>\n",
       "      <td>5</td>\n",
       "      <td>R3G1NU4RZK81EE</td>\n",
       "      <td>really slick and stays slick longtime, looks l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816406</th>\n",
       "      <td>5</td>\n",
       "      <td>R1A8YXRY5K3PUZ</td>\n",
       "      <td>Amazing keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41078916</th>\n",
       "      <td>3</td>\n",
       "      <td>R27ZXYR2VCVJCJ</td>\n",
       "      <td>too small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067910</th>\n",
       "      <td>3</td>\n",
       "      <td>R30L5DD2UV4M1V</td>\n",
       "      <td>A decent book to read with a child. It lists a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971383</th>\n",
       "      <td>3</td>\n",
       "      <td>R26FY6PNPTSNWL</td>\n",
       "      <td>Doesn't fit my trailer hitch, but looks like i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086759</th>\n",
       "      <td>4</td>\n",
       "      <td>R3T7XAOULCY5NY</td>\n",
       "      <td>I was a little skeptical at first thinking thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          star_rating       review_id  \\\n",
       "37360958            3  R14JRWZPN9JJ8O   \n",
       "32193167            4  R3S1ZGKY8EQN9P   \n",
       "13272080            5  R2IQ1375QDFGIG   \n",
       "1404381             5  R1NV59K55BHI0O   \n",
       "6026917             5  R3G1NU4RZK81EE   \n",
       "...               ...             ...   \n",
       "39816406            5  R1A8YXRY5K3PUZ   \n",
       "41078916            3  R27ZXYR2VCVJCJ   \n",
       "7067910             3  R30L5DD2UV4M1V   \n",
       "20971383            3  R26FY6PNPTSNWL   \n",
       "3086759             4  R3T7XAOULCY5NY   \n",
       "\n",
       "                                                review_body  \n",
       "37360958  A bit goofy. Makes some good political points....  \n",
       "32193167                  5-star performance, 2-star price.  \n",
       "13272080                                       Excelente!!!  \n",
       "1404381   first of all this book is very helpful it help...  \n",
       "6026917   really slick and stays slick longtime, looks l...  \n",
       "...                                                     ...  \n",
       "39816406                                   Amazing keyboard  \n",
       "41078916                                          too small  \n",
       "7067910   A decent book to read with a child. It lists a...  \n",
       "20971383  Doesn't fit my trailer hitch, but looks like i...  \n",
       "3086759   I was a little skeptical at first thinking thi...  \n",
       "\n",
       "[400000 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f15b84a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df Memory Usage: 11.584748897701502 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"df Memory Usage: {df.memory_usage(deep=True).sum() / 1024**3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7661cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51a983f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input クラスを使用して、データからサンプルを作成する。\n",
    "train_inputs = train_df.apply(\n",
    "    lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd1179aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input クラスを使用して、データからサンプルを作成する。\n",
    "validation_inputs = validation_df.apply(\n",
    "    lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandarallel import pandarallel\n",
    "# import os\n",
    "# os.environ['JOBLIB_TEMP_FOLDER'] = '/tmp'\n",
    "# !pip3 install --no-cache-dir accelerate\n",
    "# pandarallel.initialize(nb_workers=2, progress_bar=True, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def func(x):\n",
    "#    return lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp)\n",
    "\n",
    "# inputs = df.parallel_apply(\n",
    "#     lambda x: Input(label=x[LABEL_COLUMN], text=x[REVIEW_BODY_COLUMN], review_id=x[REVIEW_ID_COLUMN], date=timestamp),\n",
    "#     axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1f93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f049d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32961526    <__main__.Input object at 0x7f0c154295a0>\n",
       "30241700    <__main__.Input object at 0x7f0c1542a410>\n",
       "8845194     <__main__.Input object at 0x7f0c15429f90>\n",
       "34884730    <__main__.Input object at 0x7f0c1542a470>\n",
       "33577116    <__main__.Input object at 0x7f0c15429990>\n",
       "                              ...                    \n",
       "32866146    <__main__.Input object at 0x7f1059ad7670>\n",
       "22333198    <__main__.Input object at 0x7f1059ad76d0>\n",
       "33572301    <__main__.Input object at 0x7f1059ad7730>\n",
       "20664178    <__main__.Input object at 0x7f1059ad7790>\n",
       "481666      <__main__.Input object at 0x7f1059ad77f0>\n",
       "Length: 2000000, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aea980b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_file = \"/mnt/train_data.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40830e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_output_file = \"/mnt/validation_data.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date が Feature Store の仕様に合わせて ISO-8601 になっていることを確認\n",
    "# print(train_inputs[0].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4675747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input 0 of 2000000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input 10000 of 2000000\n",
      "\n",
      "Writing input 20000 of 2000000\n",
      "\n",
      "Writing input 30000 of 2000000\n",
      "\n",
      "Writing input 40000 of 2000000\n",
      "\n",
      "Writing input 50000 of 2000000\n",
      "\n",
      "Writing input 60000 of 2000000\n",
      "\n",
      "Writing input 70000 of 2000000\n",
      "\n",
      "Writing input 80000 of 2000000\n",
      "\n",
      "Writing input 90000 of 2000000\n",
      "\n",
      "Writing input 100000 of 2000000\n",
      "\n",
      "Writing input 110000 of 2000000\n",
      "\n",
      "Writing input 120000 of 2000000\n",
      "\n",
      "Writing input 130000 of 2000000\n",
      "\n",
      "Writing input 140000 of 2000000\n",
      "\n",
      "Writing input 150000 of 2000000\n",
      "\n",
      "Writing input 160000 of 2000000\n",
      "\n",
      "Writing input 170000 of 2000000\n",
      "\n",
      "Writing input 180000 of 2000000\n",
      "\n",
      "Writing input 190000 of 2000000\n",
      "\n",
      "Writing input 200000 of 2000000\n",
      "\n",
      "Writing input 210000 of 2000000\n",
      "\n",
      "Writing input 220000 of 2000000\n",
      "\n",
      "Writing input 230000 of 2000000\n",
      "\n",
      "Writing input 240000 of 2000000\n",
      "\n",
      "Writing input 250000 of 2000000\n",
      "\n",
      "Writing input 260000 of 2000000\n",
      "\n",
      "Writing input 270000 of 2000000\n",
      "\n",
      "Writing input 280000 of 2000000\n",
      "\n",
      "Writing input 290000 of 2000000\n",
      "\n",
      "Writing input 300000 of 2000000\n",
      "\n",
      "Writing input 310000 of 2000000\n",
      "\n",
      "Writing input 320000 of 2000000\n",
      "\n",
      "Writing input 330000 of 2000000\n",
      "\n",
      "Writing input 340000 of 2000000\n",
      "\n",
      "Writing input 350000 of 2000000\n",
      "\n",
      "Writing input 360000 of 2000000\n",
      "\n",
      "Writing input 370000 of 2000000\n",
      "\n",
      "Writing input 380000 of 2000000\n",
      "\n",
      "Writing input 390000 of 2000000\n",
      "\n",
      "Writing input 400000 of 2000000\n",
      "\n",
      "Writing input 410000 of 2000000\n",
      "\n",
      "Writing input 420000 of 2000000\n",
      "\n",
      "Writing input 430000 of 2000000\n",
      "\n",
      "Writing input 440000 of 2000000\n",
      "\n",
      "Writing input 450000 of 2000000\n",
      "\n",
      "Writing input 460000 of 2000000\n",
      "\n",
      "Writing input 470000 of 2000000\n",
      "\n",
      "Writing input 480000 of 2000000\n",
      "\n",
      "Writing input 490000 of 2000000\n",
      "\n",
      "Writing input 500000 of 2000000\n",
      "\n",
      "Writing input 510000 of 2000000\n",
      "\n",
      "Writing input 520000 of 2000000\n",
      "\n",
      "Writing input 530000 of 2000000\n",
      "\n",
      "Writing input 540000 of 2000000\n",
      "\n",
      "Writing input 550000 of 2000000\n",
      "\n",
      "Writing input 560000 of 2000000\n",
      "\n",
      "Writing input 570000 of 2000000\n",
      "\n",
      "Writing input 580000 of 2000000\n",
      "\n",
      "Writing input 590000 of 2000000\n",
      "\n",
      "Writing input 600000 of 2000000\n",
      "\n",
      "Writing input 610000 of 2000000\n",
      "\n",
      "Writing input 620000 of 2000000\n",
      "\n",
      "Writing input 630000 of 2000000\n",
      "\n",
      "Writing input 640000 of 2000000\n",
      "\n",
      "Writing input 650000 of 2000000\n",
      "\n",
      "Writing input 660000 of 2000000\n",
      "\n",
      "Writing input 670000 of 2000000\n",
      "\n",
      "Writing input 680000 of 2000000\n",
      "\n",
      "Writing input 690000 of 2000000\n",
      "\n",
      "Writing input 700000 of 2000000\n",
      "\n",
      "Writing input 710000 of 2000000\n",
      "\n",
      "Writing input 720000 of 2000000\n",
      "\n",
      "Writing input 730000 of 2000000\n",
      "\n",
      "Writing input 740000 of 2000000\n",
      "\n",
      "Writing input 750000 of 2000000\n",
      "\n",
      "Writing input 760000 of 2000000\n",
      "\n",
      "Writing input 770000 of 2000000\n",
      "\n",
      "Writing input 780000 of 2000000\n",
      "\n",
      "Writing input 790000 of 2000000\n",
      "\n",
      "Writing input 800000 of 2000000\n",
      "\n",
      "Writing input 810000 of 2000000\n",
      "\n",
      "Writing input 820000 of 2000000\n",
      "\n",
      "Writing input 830000 of 2000000\n",
      "\n",
      "Writing input 840000 of 2000000\n",
      "\n",
      "Writing input 850000 of 2000000\n",
      "\n",
      "Writing input 860000 of 2000000\n",
      "\n",
      "Writing input 870000 of 2000000\n",
      "\n",
      "Writing input 880000 of 2000000\n",
      "\n",
      "Writing input 890000 of 2000000\n",
      "\n",
      "Writing input 900000 of 2000000\n",
      "\n",
      "Writing input 910000 of 2000000\n",
      "\n",
      "Writing input 920000 of 2000000\n",
      "\n",
      "Writing input 930000 of 2000000\n",
      "\n",
      "Writing input 940000 of 2000000\n",
      "\n",
      "Writing input 950000 of 2000000\n",
      "\n",
      "Writing input 960000 of 2000000\n",
      "\n",
      "Writing input 970000 of 2000000\n",
      "\n",
      "Writing input 980000 of 2000000\n",
      "\n",
      "Writing input 990000 of 2000000\n",
      "\n",
      "Writing input 1000000 of 2000000\n",
      "\n",
      "Writing input 1010000 of 2000000\n",
      "\n",
      "Writing input 1020000 of 2000000\n",
      "\n",
      "Writing input 1030000 of 2000000\n",
      "\n",
      "Writing input 1040000 of 2000000\n",
      "\n",
      "Writing input 1050000 of 2000000\n",
      "\n",
      "Writing input 1060000 of 2000000\n",
      "\n",
      "Writing input 1070000 of 2000000\n",
      "\n",
      "Writing input 1080000 of 2000000\n",
      "\n",
      "Writing input 1090000 of 2000000\n",
      "\n",
      "Writing input 1100000 of 2000000\n",
      "\n",
      "Writing input 1110000 of 2000000\n",
      "\n",
      "Writing input 1120000 of 2000000\n",
      "\n",
      "Writing input 1130000 of 2000000\n",
      "\n",
      "Writing input 1140000 of 2000000\n",
      "\n",
      "Writing input 1150000 of 2000000\n",
      "\n",
      "Writing input 1160000 of 2000000\n",
      "\n",
      "Writing input 1170000 of 2000000\n",
      "\n",
      "Writing input 1180000 of 2000000\n",
      "\n",
      "Writing input 1190000 of 2000000\n",
      "\n",
      "Writing input 1200000 of 2000000\n",
      "\n",
      "Writing input 1210000 of 2000000\n",
      "\n",
      "Writing input 1220000 of 2000000\n",
      "\n",
      "Writing input 1230000 of 2000000\n",
      "\n",
      "Writing input 1240000 of 2000000\n",
      "\n",
      "Writing input 1250000 of 2000000\n",
      "\n",
      "Writing input 1260000 of 2000000\n",
      "\n",
      "Writing input 1270000 of 2000000\n",
      "\n",
      "Writing input 1280000 of 2000000\n",
      "\n",
      "Writing input 1290000 of 2000000\n",
      "\n",
      "Writing input 1300000 of 2000000\n",
      "\n",
      "Writing input 1310000 of 2000000\n",
      "\n",
      "Writing input 1320000 of 2000000\n",
      "\n",
      "Writing input 1330000 of 2000000\n",
      "\n",
      "Writing input 1340000 of 2000000\n",
      "\n",
      "Writing input 1350000 of 2000000\n",
      "\n",
      "Writing input 1360000 of 2000000\n",
      "\n",
      "Writing input 1370000 of 2000000\n",
      "\n",
      "Writing input 1380000 of 2000000\n",
      "\n",
      "Writing input 1390000 of 2000000\n",
      "\n",
      "Writing input 1400000 of 2000000\n",
      "\n",
      "Writing input 1410000 of 2000000\n",
      "\n",
      "Writing input 1420000 of 2000000\n",
      "\n",
      "Writing input 1430000 of 2000000\n",
      "\n",
      "Writing input 1440000 of 2000000\n",
      "\n",
      "Writing input 1450000 of 2000000\n",
      "\n",
      "Writing input 1460000 of 2000000\n",
      "\n",
      "Writing input 1470000 of 2000000\n",
      "\n",
      "Writing input 1480000 of 2000000\n",
      "\n",
      "Writing input 1490000 of 2000000\n",
      "\n",
      "Writing input 1500000 of 2000000\n",
      "\n",
      "Writing input 1510000 of 2000000\n",
      "\n",
      "Writing input 1520000 of 2000000\n",
      "\n",
      "Writing input 1530000 of 2000000\n",
      "\n",
      "Writing input 1540000 of 2000000\n",
      "\n",
      "Writing input 1550000 of 2000000\n",
      "\n",
      "Writing input 1560000 of 2000000\n",
      "\n",
      "Writing input 1570000 of 2000000\n",
      "\n",
      "Writing input 1580000 of 2000000\n",
      "\n",
      "Writing input 1590000 of 2000000\n",
      "\n",
      "Writing input 1600000 of 2000000\n",
      "\n",
      "Writing input 1610000 of 2000000\n",
      "\n",
      "Writing input 1620000 of 2000000\n",
      "\n",
      "Writing input 1630000 of 2000000\n",
      "\n",
      "Writing input 1640000 of 2000000\n",
      "\n",
      "Writing input 1650000 of 2000000\n",
      "\n",
      "Writing input 1660000 of 2000000\n",
      "\n",
      "Writing input 1670000 of 2000000\n",
      "\n",
      "Writing input 1680000 of 2000000\n",
      "\n",
      "Writing input 1690000 of 2000000\n",
      "\n",
      "Writing input 1700000 of 2000000\n",
      "\n",
      "Writing input 1710000 of 2000000\n",
      "\n",
      "Writing input 1720000 of 2000000\n",
      "\n",
      "Writing input 1730000 of 2000000\n",
      "\n",
      "Writing input 1740000 of 2000000\n",
      "\n",
      "Writing input 1750000 of 2000000\n",
      "\n",
      "Writing input 1760000 of 2000000\n",
      "\n",
      "Writing input 1770000 of 2000000\n",
      "\n",
      "Writing input 1780000 of 2000000\n",
      "\n",
      "Writing input 1790000 of 2000000\n",
      "\n",
      "Writing input 1800000 of 2000000\n",
      "\n",
      "Writing input 1810000 of 2000000\n",
      "\n",
      "Writing input 1820000 of 2000000\n",
      "\n",
      "Writing input 1830000 of 2000000\n",
      "\n",
      "Writing input 1840000 of 2000000\n",
      "\n",
      "Writing input 1850000 of 2000000\n",
      "\n",
      "Writing input 1860000 of 2000000\n",
      "\n",
      "Writing input 1870000 of 2000000\n",
      "\n",
      "Writing input 1880000 of 2000000\n",
      "\n",
      "Writing input 1890000 of 2000000\n",
      "\n",
      "Writing input 1900000 of 2000000\n",
      "\n",
      "Writing input 1910000 of 2000000\n",
      "\n",
      "Writing input 1920000 of 2000000\n",
      "\n",
      "Writing input 1930000 of 2000000\n",
      "\n",
      "Writing input 1940000 of 2000000\n",
      "\n",
      "Writing input 1950000 of 2000000\n",
      "\n",
      "Writing input 1960000 of 2000000\n",
      "\n",
      "Writing input 1970000 of 2000000\n",
      "\n",
      "Writing input 1980000 of 2000000\n",
      "\n",
      "Writing input 1990000 of 2000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_records = transform_inputs_to_tfrecord(train_inputs, train_output_file, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4135685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input 0 of 400000\n",
      "\n",
      "Writing input 10000 of 400000\n",
      "\n",
      "Writing input 20000 of 400000\n",
      "\n",
      "Writing input 30000 of 400000\n",
      "\n",
      "Writing input 40000 of 400000\n",
      "\n",
      "Writing input 50000 of 400000\n",
      "\n",
      "Writing input 60000 of 400000\n",
      "\n",
      "Writing input 70000 of 400000\n",
      "\n",
      "Writing input 80000 of 400000\n",
      "\n",
      "Writing input 90000 of 400000\n",
      "\n",
      "Writing input 100000 of 400000\n",
      "\n",
      "Writing input 110000 of 400000\n",
      "\n",
      "Writing input 120000 of 400000\n",
      "\n",
      "Writing input 130000 of 400000\n",
      "\n",
      "Writing input 140000 of 400000\n",
      "\n",
      "Writing input 150000 of 400000\n",
      "\n",
      "Writing input 160000 of 400000\n",
      "\n",
      "Writing input 170000 of 400000\n",
      "\n",
      "Writing input 180000 of 400000\n",
      "\n",
      "Writing input 190000 of 400000\n",
      "\n",
      "Writing input 200000 of 400000\n",
      "\n",
      "Writing input 210000 of 400000\n",
      "\n",
      "Writing input 220000 of 400000\n",
      "\n",
      "Writing input 230000 of 400000\n",
      "\n",
      "Writing input 240000 of 400000\n",
      "\n",
      "Writing input 250000 of 400000\n",
      "\n",
      "Writing input 260000 of 400000\n",
      "\n",
      "Writing input 270000 of 400000\n",
      "\n",
      "Writing input 280000 of 400000\n",
      "\n",
      "Writing input 290000 of 400000\n",
      "\n",
      "Writing input 300000 of 400000\n",
      "\n",
      "Writing input 310000 of 400000\n",
      "\n",
      "Writing input 320000 of 400000\n",
      "\n",
      "Writing input 330000 of 400000\n",
      "\n",
      "Writing input 340000 of 400000\n",
      "\n",
      "Writing input 350000 of 400000\n",
      "\n",
      "Writing input 360000 of 400000\n",
      "\n",
      "Writing input 370000 of 400000\n",
      "\n",
      "Writing input 380000 of 400000\n",
      "\n",
      "Writing input 390000 of 400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_records = transform_inputs_to_tfrecord(validation_inputs, validation_output_file, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19164a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2c5796a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e7d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
